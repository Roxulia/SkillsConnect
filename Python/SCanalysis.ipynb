{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import seaborn as sbn\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Task Catagories.csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = train_data.Skill.unique()\n",
    "print(len(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_data.Skill.value_counts()\n",
    "skills  = a[a<10].index\n",
    "filtered_data = train_data[train_data['Skill'].isin(skills)]\n",
    "\n",
    "train_data = train_data.drop(filtered_data.index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Skill'] = train_data['Skill'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['cloud','devops','deployment']\n",
    "b = ['ai/ml','data science']\n",
    "train_data['Category'] = train_data['Category'].apply(lambda x : 'Cloud & Deployment' if x in a else 'DataScience & AI' if x in b else 'database' if x == 'database administration' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data[\"Skill\"].str.contains(\"sql\"),'Category'] = 'database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = train_data[train_data['Category'] == 'database']\n",
    "database.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = train_data[train_data['Category'] == 'backend']\n",
    "backend.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = train_data[train_data['Category'] == 'cloud']\n",
    "cloud.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datascience = train_data[train_data['Category'] == 'data science']\n",
    "datascience.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataadmin = train_data[train_data['Category'] == 'database administration']\n",
    "dataadmin.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiml = train_data[train_data['Category'] == 'ai/ml']\n",
    "aiml.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = train_data[train_data['Category'] == 'deployment']\n",
    "deployment.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devops = train_data[train_data['Category'] == 'devops']\n",
    "devops.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentation = train_data[train_data['Category'] == 'documentation']\n",
    "documentation.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend = train_data[train_data['Category'] == 'frontend']\n",
    "frontend.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectManagement = train_data[train_data['Category'] == 'project management']\n",
    "projectManagement.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = train_data[train_data['Category'] == 'testing']\n",
    "testing.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uiux = train_data[train_data['Category'] == 'ui/ux design']\n",
    "uiux.Skill.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarity(detail):\n",
    "    data = list(train_data['Task Description'])\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([detail] + data)\n",
    "    cos = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1:])\n",
    "    return cos[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(train_data['Task Description'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = getSimilarity(\"Create a Backend and Generate API\")\n",
    "for i, score in enumerate(a):\n",
    "    print(f\"Query vs Document {i+1}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(detail,category=[],skill=set()):\n",
    "    similarity = getSimilarity(detail)\n",
    "    data = train_data.loc[train_data['Category'].isin(category),'Skill']\n",
    "    required_skill = set(data['Skill'].unique())\n",
    "    skillPoint = len(list(required_skill & skill))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_required_by_category = {\n",
    "    'Backend' : {'Java','Python','C++'},\n",
    "    'Frontend' : {'CSS','HTML','React'},\n",
    "    'Database' : {'MySQL','MongoDB','Redis'},\n",
    "    'AI & ML' : {'TensorFlow','Pytorch'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_users(project_description, project_categories, users, category_skills, \n",
    "                     similarity_weight=0.4, skill_weight=0.4, rating_weight=0.2):\n",
    "    \"\"\"\n",
    "    Recommends the best users for a given project.\n",
    "    \n",
    "    Parameters:\n",
    "    - project_description (str): The description of the project.\n",
    "    - project_categories (list): List of categories related to the project.\n",
    "    - users (list): A list of user dictionaries containing:\n",
    "        - 'id': Unique user ID.\n",
    "        - 'finished_projects': List of { 'description': str, 'category': str }.\n",
    "        - 'skills': List of skills.\n",
    "        - 'rating': Numeric rating of the user.\n",
    "    - category_skills (dict): Mapping of categories to required skills.\n",
    "    - similarity_weight (float): Weight for project similarity score.\n",
    "    - skill_weight (float): Weight for skill matching score.\n",
    "    - rating_weight (float): Weight for user rating.\n",
    "\n",
    "    Returns:\n",
    "    - List of top recommended users sorted by their score.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_scores = []\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Compute TF-IDF for the given project description\n",
    "    project_desc_tfidf = vectorizer.fit_transform([project_description])\n",
    "\n",
    "    for user in users:\n",
    "        # 1️⃣ **Cosine Similarity Score** (Between Project & User’s Finished Projects)\n",
    "        user_projects = [p[\"description\"] for p in user[\"finished_projects\"]]\n",
    "        \n",
    "        if user_projects:\n",
    "            user_tfidf = vectorizer.transform(user_projects)\n",
    "            similarity_scores = cosine_similarity(project_desc_tfidf, user_tfidf)\n",
    "            max_similarity = np.max(similarity_scores)  # Best match\n",
    "        else:\n",
    "            max_similarity = 0  # No finished projects\n",
    "\n",
    "        # 2️⃣ **Skill Match Score**\n",
    "        user_skills = set(user[\"skills\"])\n",
    "        required_skills = set()\n",
    "        for category in project_categories:\n",
    "            required_skills.update(category_skills.get(category, []))\n",
    "\n",
    "        if required_skills:\n",
    "            skill_score = len(user_skills & required_skills) / len(required_skills)\n",
    "        else:\n",
    "            skill_score = 0  # No category-specific skills\n",
    "\n",
    "        # 3️⃣ **User Rating (Normalized)**\n",
    "        normalized_rating = user[\"rating\"] / 5.0  # Assuming rating is out of 5\n",
    "\n",
    "        # 4️⃣ **Final Weighted Score Calculation**\n",
    "        final_score = (\n",
    "            (similarity_weight * max_similarity) + \n",
    "            (skill_weight * skill_score) + \n",
    "            (rating_weight * normalized_rating)\n",
    "        )\n",
    "\n",
    "        user_scores.append({\"id\": user[\"id\"], \"score\": float(final_score)})\n",
    "\n",
    "    # Sort Users by Score (Descending)\n",
    "    user_scores = sorted(user_scores, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return user_scores[:3]  # Return Top 3 Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_projects(projects, category_skills, user_skills, user_finished_projects, similarity_weight=0.35, skill_weight=0.65, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend projects based on similarity to user's finished projects and skill match.\n",
    "    \n",
    "    Parameters:\n",
    "    - projects: List of dicts, each with 'description' and 'category'.\n",
    "    - category_skills: Dict mapping category names to required skills.\n",
    "    - user_skills: List of user's skills.\n",
    "    - user_finished_projects: List of dicts with 'description' and 'category'.\n",
    "    - similarity_weight: Weight for cosine similarity (default 0.6).\n",
    "    - skill_weight: Weight for skill matching (default 0.4).\n",
    "    - top_n: Number of top recommendations to return (default 3).\n",
    "    \n",
    "    Returns:\n",
    "    - List of top_n recommended projects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ---------------- Step 1: Cosine Similarity Calculation ----------------\n",
    "    if(not user_finished_projects == []):\n",
    "        all_descriptions = [proj[\"Task Description\"] for proj in projects] + [proj[\"Task Description\"] for proj in user_finished_projects]\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(all_descriptions)\n",
    "\n",
    "        project_similarities = []\n",
    "        for i, project in enumerate(projects):\n",
    "            similarity_scores = cosine_similarity(tfidf_matrix[i], tfidf_matrix[len(projects):]).flatten()\n",
    "            project_similarities.append(max(similarity_scores))  # Max similarity with any user project\n",
    "\n",
    "        # Normalize similarity scores\n",
    "        max_sim = max(project_similarities) if max(project_similarities) > 0 else 1\n",
    "        project_similarities = [sim / max_sim for sim in project_similarities]\n",
    "\n",
    "        all_category = [proj[\"Category\"] for proj in projects] + [proj[\"Category\"] for proj in user_finished_projects]\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(all_category)\n",
    "\n",
    "        category_similarities = []\n",
    "        for i, project in enumerate(projects):\n",
    "            similarity_scores = cosine_similarity(tfidf_matrix[i], tfidf_matrix[len(projects):]).flatten()\n",
    "            category_similarities.append(max(similarity_scores))  # Max similarity with any user project\n",
    "\n",
    "        # Normalize similarity scores\n",
    "        max_sim = max(category_similarities) if max(category_similarities) > 0 else 1\n",
    "        category_similarities = [sim / max_sim for sim in category_similarities]\n",
    "\n",
    "        # ---------------- Step 2: Skill Matching Score ----------------\n",
    "        skill_match_scores = []\n",
    "        for project in projects:\n",
    "            category = project[\"Category\"]\n",
    "            required_skills = category_skills.get(category, [])\n",
    "            matching_skills = len(set(required_skills) & set(user_skills))\n",
    "            \n",
    "            # Normalize skill match score\n",
    "            skill_match_score = matching_skills / len(required_skills) if required_skills else 0\n",
    "            skill_match_scores.append(skill_match_score)\n",
    "\n",
    "        # ---------------- Step 3: Combine Scores and Sort ----------------\n",
    "        final_scores = [\n",
    "             similarity_weight*proj_sim +  skill_match * skill_weight + 0.5 * cate\n",
    "            for proj_sim, skill_match ,cate in zip(project_similarities, skill_match_scores,category_similarities)\n",
    "        ]\n",
    "\n",
    "        # Sort projects by final score\n",
    "        sorted_projects = sorted(zip(projects, final_scores), key=lambda x: x[1], reverse=True)\n",
    "    else:\n",
    "        # ---------------- Step 2: Skill Matching Score ----------------\n",
    "        skill_match_scores = []\n",
    "        for project in projects:\n",
    "            category = project[\"Category\"]\n",
    "            required_skills = category_skills.get(category, [])\n",
    "            matching_skills = len(set(required_skills) & set(user_skills))\n",
    "            \n",
    "            # Normalize skill match score\n",
    "            skill_match_score = matching_skills / len(required_skills) if required_skills else 0\n",
    "            skill_match_scores.append(skill_match_score)\n",
    "\n",
    "        # ---------------- Step 3: Combine Scores and Sort ----------------\n",
    "        final_scores = [\n",
    "            skill_match*skill_weight\n",
    "            for  skill_match in skill_match_scores\n",
    "        ]\n",
    "\n",
    "        # Sort projects by final score\n",
    "        sorted_projects = sorted(zip(projects, final_scores), key=lambda x: x[1], reverse=True)\n",
    "    # Return top N recommended projects\n",
    "    return [proj[0] for proj in sorted_projects[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = train_data[['Task Description','Category']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = [{'Task Description': 'Implement user authentication', 'Category': 'backend'},\n",
    " {'Task Description': 'Create a Button', 'Category': 'frontend'},\n",
    " {'Task Description': 'Manage database operations', 'Category': 'database'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_skills = train_data.groupby('Category')['Skill'].agg(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_finished = [{'Task Description': 'Create a responsive website', 'Category': 'frontend'},\n",
    "\n",
    " {'Task Description': 'Develop a mobile-first UI', 'Category': 'frontend'}]\n",
    "user_skill = ['java','css','figma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = recommend_projects(projects,category_skills,user_skill,user_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏗️ Sample Project Data\n",
    "project_description = \"Develop a deep learning model for object detection\"\n",
    "project_categories = [\"DataScience & AI\"]\n",
    "\n",
    "# 📜 Sample User Data\n",
    "users = [\n",
    "    {\"id\": 6, \"finished_projects\": [{\"description\": \"Built an AI model for skin detection\", \"category\": \"DataScience & AI\"}],\n",
    "     \"skills\": [\"python\", \"tensorflow\"], \"rating\": 4.8},\n",
    "    \n",
    "    {\"id\": 2, \"finished_projects\": [{\"description\": \"Developed a machine learning chatbot\", \"category\": \"frontend\"}],\n",
    "     \"skills\": [\"python\", \"css\", \"figma\"], \"rating\": 4.5},\n",
    "    \n",
    "    {\"id\": 3, \"finished_projects\": [{\"description\": \"Created a blockchain-based voting system\", \"category\": \"backend\"}],\n",
    "     \"skills\": [\"Solidity\", \"Smart Contracts\"], \"rating\": 4.9}\n",
    "]\n",
    "recommended_users = recommend_users(project_description, project_categories, users, category_skills)\n",
    "\n",
    "print(recommended_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load CSV data\n",
    "df = pd.read_csv(\"recommendation_data.csv\")\n",
    "\n",
    "# Deserialize JSON fields\n",
    "df[\"user_skills\"] = df[\"user_skills\"].apply(json.loads)\n",
    "df[\"user_finished_projects\"] = df[\"user_finished_projects\"].apply(json.loads)\n",
    "df[\"relevant_projects\"] = df[\"relevant_projects\"].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calculate_metrics(recommended_projects, relevant_projects, top_n):\n",
    "    \"\"\"\n",
    "    Calculate Precision@N, Recall@N, and F1-Score@N.\n",
    "    \"\"\"\n",
    "    if top_n == 0:  # Avoid division by zero\n",
    "        return None, None, None  \n",
    "\n",
    "    # Get category counts for relevant projects\n",
    "    relevant_counts = Counter(proj[\"Category\"] for proj in relevant_projects)\n",
    "    print(relevant_counts)\n",
    "\n",
    "    # Count true positives by matching categories\n",
    "    true_positives = 0\n",
    "    for proj in recommended_projects[:top_n]:\n",
    "        if relevant_counts[proj[\"Category\"]] > 0:\n",
    "            true_positives += 1\n",
    "            relevant_counts[proj[\"Category\"]] -=1\n",
    "    #true_positives = sum(1 for proj in recommended_projects[:top_n] if relevant_counts[proj[\"Category\"]] > 0)\n",
    "    print(true_positives)\n",
    "    # Compute precision and recall\n",
    "    precision = true_positives / top_n if top_n > 0 else None\n",
    "    recall = true_positives / len(relevant_projects) if len(relevant_projects) > 0 else None\n",
    "\n",
    "    # Compute F1-score\n",
    "    f1_score = (\n",
    "        2 * (precision * recall) / (precision + recall) \n",
    "        if precision is not None and recall is not None and (precision + recall) > 0 \n",
    "        else None\n",
    "    )\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "#calculate_metrics(recommended_projects,relevant_projects,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dicts = [dict(t) for t in {tuple(d.items()) for d in projects}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "\n",
    "# Iterate over all users\n",
    "for _, user in df.iterrows():\n",
    "    # Get user data\n",
    "    user_skills = user[\"user_skills\"]\n",
    "    user_finished_projects = user[\"user_finished_projects\"]\n",
    "    relevant_projects = user[\"relevant_projects\"]\n",
    "    \n",
    "    # Run the recommendation algorithm\n",
    "    recommended_projects = recommend_projects(\n",
    "        unique_dicts,\n",
    "        category_skills,\n",
    "        user_skills,\n",
    "        user_finished_projects,  \n",
    "        top_n=10\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision, recall, f1 = calculate_metrics(\n",
    "        recommended_projects,\n",
    "        relevant_projects,\n",
    "        top_n=10\n",
    "    )\n",
    "    \n",
    "    # Store metrics\n",
    "    all_metrics.append({\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metrics to a DataFrame\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "# Calculate mean values\n",
    "average_precision = metrics_df[\"precision\"].mean()\n",
    "average_recall = metrics_df[\"recall\"].mean()\n",
    "average_f1 = metrics_df[\"f1_score\"].mean()\n",
    "\n",
    "print(f\"Average Precision@3: {average_precision:.2f}\")\n",
    "print(f\"Average Recall@3: {average_recall:.2f}\")\n",
    "print(f\"Average F1-Score@3: {average_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Connect to MySQL\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\",       # Replace with your MySQL host (e.g., \"127.0.0.1\")\n",
    "    user=\"root\",   # Your MySQL username\n",
    "    password=\"\", # Your MySQL password\n",
    "    database=\"skillsconnect\"  # Your database name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a cursor object\n",
    "\n",
    "\n",
    "# Example query: fetch all data from a table\n",
    "for x in train_data.Skill.unique():\n",
    "    try:\n",
    "        # Use parameterized query to prevent SQL injection\n",
    "        cursor.execute(\"INSERT INTO skill (name) VALUES (%s)\", (x,))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting skill '{x}': {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_data.Category.unique():\n",
    "    try:\n",
    "        # Use parameterized query to prevent SQL injection\n",
    "        cursor.execute(\"INSERT INTO category (name) VALUES (%s)\", (x,))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting category '{x}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the changes to the database\n",
    "connection.commit()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Category' and count the occurrences of each skill within each category\n",
    "category_skill_counts = (\n",
    "    train_data.groupby('Category')['Skill']\n",
    "    .apply(lambda x: x.str.split(',').explode().str.strip().value_counts())\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "category_skill_counts_df = category_skill_counts.reset_index()\n",
    "category_skill_counts_df.columns = ['Category', 'Skill', 'Count']\n",
    "print(category_skill_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Skill'] = train_data['Skill'].str.split(',')  # Split skills into lists\n",
    "skills_per_category = (\n",
    "    train_data.explode('Skill')  # Create separate rows for each skill\n",
    "    .assign(Skill=lambda df: df['Skill'].str.strip())  # Remove leading/trailing spaces\n",
    "    .groupby(['Category', 'Skill'])\n",
    "    .size()\n",
    "    .reset_index(name='Count')  # Reset index and rename the count column\n",
    ")\n",
    "\n",
    "# Visualize the skill counts per category\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "categories = skills_per_category['Category'].unique()\n",
    "\n",
    "# Create a bar chart for each category\n",
    "for category in categories:\n",
    "    category_data = skills_per_category[skills_per_category['Category'] == category]\n",
    "    ax.bar(category_data['Skill'], category_data['Count'], label=category)\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_title('Skill Counts by Category', fontsize=16)\n",
    "ax.set_xlabel('Skills', fontsize=14)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.legend(title='Category', fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the visualization\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
